{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["intraday-ml: intraday_ml_model_fit.py"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import datetime"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import sklearn\n", "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n", "from sklearn.ensemble import (\n", "    BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n", ")\n", "from sklearn.externals import joblib\n", "from sklearn.metrics import confusion_matrix\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.tree import DecisionTreeClassifier"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_up_down_dataframe(\n", "    csv_filepath,\n", "    lookback_minutes=30,\n", "    lookforward_minutes=5,\n", "    up_down_factor=2.0,\n", "    percent_factor=0.01,\n", "    start=None, end=None\n", "):\n", "    \"\"\"\n", "    Creates a Pandas DataFrame that imports and calculates\n", "    the percentage returns of an intraday OLHC ticker from disk.\n", "    'lookback_minutes' of prior returns are stored to create\n", "    a feature vector, while 'lookforward_minutes' are used to\n", "    ascertain how far in the future to predict across.\n", "    The actual prediction is to determine whether a ticker\n", "    moves up by at least 'up_down_factor' x 'percent_factor',\n", "    while not dropping below 'percent_factor' in the same period.\n", "    i.e. Does the stock move up 1% in a minute and not down by 0.5%?\n", "    The DataFrame will consist of 'lookback_minutes' columns for feature\n", "    vectors and one column for whether the stock adheres to the \"up/down\"\n", "    rule, which is 1 if True or 0 if False for each minute.\n", "    \"\"\"\n", "    ts = pd.read_csv(\n", "        csv_filepath,\n", "        names=[\n", "            \"Timestamp\", \"Open\", \"Low\", \"High\",\n", "            \"Close\", \"Volume\", \"OpenInterest\"\n", "        ],\n", "        index_col=\"Timestamp\", parse_dates=True\n", "    )\n\n", "    # Filter on start/end dates\n", "    if start is not None:\n", "        ts = ts[ts.index >= start]\n", "    if end is not None:\n", "        ts = ts[ts.index <= end]\n\n", "    # Drop the non-essential columns\n", "    ts.drop(\n", "        [\n", "            \"Open\", \"Low\", \"High\",\n", "            \"Volume\", \"OpenInterest\"\n", "        ],\n", "        axis=1, inplace=True\n", "    )\n\n", "    # Create the lookback and lookforward shifts\n", "    for i in range(0, lookback_minutes):\n", "        ts[\"Lookback%s\" % str(i+1)] = ts[\"Close\"].shift(i+1)\n", "    for i in range(0, lookforward_minutes):\n", "        ts[\"Lookforward%s\" % str(i+1)] = ts[\"Close\"].shift(-(i+1))\n", "    ts.dropna(inplace=True)\n\n", "    # Adjust all of these values to be percentage returns\n", "    ts[\"Lookback0\"] = ts[\"Close\"].pct_change()*100.0\n", "    for i in range(0, lookback_minutes):\n", "        ts[\"Lookback%s\" % str(i+1)] = ts[\n", "            \"Lookback%s\" % str(i+1)\n", "        ].pct_change()*100.0\n", "    for i in range(0, lookforward_minutes):\n", "        ts[\"Lookforward%s\" % str(i+1)] = ts[\n", "            \"Lookforward%s\" % str(i+1)\n", "        ].pct_change()*100.0\n", "    ts.dropna(inplace=True)\n\n", "    # Determine if the stock has gone up at least by\n", "    # 'up_down_factor' x 'percent_factor' and down no more\n", "    # then 'percent_factor'\n", "    up = up_down_factor*percent_factor\n", "    down = percent_factor\n\n", "    # Create the list of True/False entries for each date\n", "    # as to whether the up/down logic is true\n", "    down_cols = [\n", "        ts[\"Lookforward%s\" % str(i+1)] > -down\n", "        for i in range(0, lookforward_minutes)\n", "    ]\n", "    up_cols = [\n", "        ts[\"Lookforward%s\" % str(i+1)] > up\n", "        for i in range(0, lookforward_minutes)\n", "    ]\n", "    # Carry out the bitwise and, as well as bitwise or\n", "    # for the down and up logic\n", "    down_tot = down_cols[0]\n", "    for c in down_cols[1:]:\n", "        down_tot = down_tot & c\n", "    up_tot = up_cols[0]\n", "    for c in up_cols[1:]:\n", "        up_tot = up_tot | c\n", "    #ts[\"UpDown\"] = down_tot & up_tot\n", "    ts[\"UpDown\"] = np.sign(ts[\"Lookforward1\"])\n\n", "    # Convert True/False into 1 and 0\n", "    ts[\"UpDown\"] = ts[\"UpDown\"].astype(int)\n", "    ts[\"UpDown\"].replace(to_replace=0, value=-1, inplace=True)\n", "    return ts"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    random_state = 42\n", "    n_estimators = 400\n", "    n_jobs = 1\n", "    csv_filepath = \"/path/to/your/AREX.csv\"\n", "    lookback_minutes = 30\n", "    lookforward_minutes = 5\n", "    print(\"Importing and creating CSV DataFrame...\")\n", "    start_date = datetime.datetime(2007, 11, 8)\n", "    end_date = datetime.datetime(2012, 12, 31)\n", "    ts = create_up_down_dataframe(\n", "        csv_filepath,\n", "        lookback_minutes=lookback_minutes,\n", "        lookforward_minutes=lookforward_minutes,\n", "        start=start_date, end=end_date\n", "    )\n\n", "    # Use the first five daily lags of AREX closing prices\n", "    print(\"Preprocessing data...\")\n", "    X = ts[\n", "        [\n", "            \"Lookback%s\" % str(i)\n", "            for i in range(0, 5)\n", "        ]\n", "    ]\n", "    y = ts[\"UpDown\"]\n\n", "    # Use the training-testing split with 70% of data in the\n", "    # training data with the remaining 30% of data in the testing\n", "    print(\"Creating train/test split of data...\")\n", "    X_train, X_test, y_train, y_test = train_test_split(\n", "        X, y, test_size=0.3, random_state=random_state\n", "    )\n", "    print(\"Fitting classifier model...\")\n", "    model = LinearDiscriminantAnalysis()\n\n", "    #model = BaggingClassifier(\n", "    #    base_estimator=DecisionTreeClassifier(),\n", "    #    n_estimators=n_estimators,\n", "    #    random_state=random_state,\n", "    #    n_jobs=n_jobs\n", "    #)\n\n", "    #model = GradientBoostingClassifier(\n", "    #    n_estimators=n_estimators,\n", "    #    random_state=random_state\n", "    #)\n\n", "    #model = RandomForestClassifier(\n", "    #    n_estimators=n_estimators,\n", "    #    n_jobs=n_jobs,\n", "    #    random_state=random_state,\n", "    #    max_depth=10\n", "    #)\n", "    model.fit(X_train, y_train)\n", "    #model.fit(X, y)\n", "    print(\"Outputting metrics...\")\n", "    print(\"Hit-Rate: %s\" % model.score(X_test, y_test))\n", "    print(\"%s\\n\" % confusion_matrix(model.predict(X_test), y_test))\n", "    print(\"Pickling model...\")\n", "    joblib.dump(model, '/path/to/your/ml_model_lda.pkl')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}