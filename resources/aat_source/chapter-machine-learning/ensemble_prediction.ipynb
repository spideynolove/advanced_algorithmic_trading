{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["decision-trees: ensemble_prediction.py"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import datetime"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import numpy as np\n", "import pandas as pd\n", "import pandas_datareader.data as web\n", "import seaborn as sns\n", "import sklearn\n", "from sklearn.ensemble import (\n", "    BaggingRegressor, RandomForestRegressor, AdaBoostRegressor\n", ")\n", "from sklearn.metrics import mean_squared_error\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import scale\n", "from sklearn.tree import DecisionTreeRegressor"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_lagged_series(symbol, start_date, end_date, lags=3):\n", "    \"\"\"\n", "    This creates a pandas DataFrame that stores \n", "    the percentage returns of the adjusted closing \n", "    value of a stock obtained from Yahoo Finance, \n", "    along with a number of lagged returns from the \n", "    prior trading days (lags defaults to 3 days).\n", "    Trading volume, as well as the Direction from \n", "    the previous day, are also included.\n", "    \"\"\"\n\n", "    # Obtain stock information from Yahoo Finance\n", "    ts = web.DataReader(\n", "        symbol, \"yahoo\", start_date, end_date\n", "    )\n\n", "    # Create the new lagged DataFrame\n", "    tslag = pd.DataFrame(index=ts.index)\n", "    tslag[\"Today\"] = ts[\"Adj Close\"]\n", "    tslag[\"Volume\"] = ts[\"Volume\"]\n\n", "    # Create the shifted lag series of \n", "    # prior trading period close values\n", "    for i in range(0,lags):\n", "        tslag[\"Lag%s\" % str(i+1)] = ts[\"Adj Close\"].shift(i+1)\n\n", "    # Create the returns DataFrame\n", "    tsret = pd.DataFrame(index=tslag.index)\n", "    tsret[\"Volume\"] = tslag[\"Volume\"]\n", "    tsret[\"Today\"] = tslag[\"Today\"].pct_change()*100.0\n\n", "    # Create the lagged percentage returns columns\n", "    for i in range(0,lags):\n", "        tsret[\"Lag%s\" % str(i+1)] = tslag[\n", "            \"Lag%s\" % str(i+1)\n", "        ].pct_change()*100.0\n", "    tsret = tsret[tsret.index >= start_date]\n", "    return tsret"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    # Set the random seed, number of estimators\n", "    # and the \"step factor\" used to plot the graph of MSE\n", "    # for each method\n", "    random_state = 42\n", "    n_jobs = 1  # Parallelisation factor for bagging, random forests\n", "    n_estimators = 1000\n", "    step_factor = 10\n", "    axis_step = int(n_estimators/step_factor)\n\n", "    # Download ten years worth of Amazon \n", "    # adjusted closing prices\n", "    start = datetime.datetime(2006, 1, 1)\n", "    end = datetime.datetime(2015, 12, 31)\n", "    amzn = create_lagged_series(\"AMZN\", start, end, lags=3)\n", "    amzn.dropna(inplace=True)\n\n", "    # Use the first three daily lags of AMZN closing prices\n", "    # and scale the data to lie within -1 and +1 for comparison\n", "    X = amzn[[\"Lag1\", \"Lag2\", \"Lag3\"]]\n", "    y = amzn[\"Today\"]\n", "    X = scale(X)\n", "    y = scale(y)\n\n", "    # Use the training-testing split with 70% of data in the\n", "    # training data with the remaining 30% of data in the testing\n", "    X_train, X_test, y_train, y_test = train_test_split(\n", "        X, y, test_size=0.3, random_state=random_state\n", "    )\n", "    \n", "    # Pre-create the arrays which will contain the MSE for\n", "    # each particular ensemble method\n", "    estimators = np.zeros(axis_step)\n", "    bagging_mse = np.zeros(axis_step)\n", "    rf_mse = np.zeros(axis_step)\n", "    boosting_mse = np.zeros(axis_step)\n\n", "    # Estimate the Bagging MSE over the full number\n", "    # of estimators, across a step size (\"step_factor\")\n", "    for i in range(0, axis_step):\n", "        print(\"Bagging Estimator: %d of %d...\" % (\n", "            step_factor*(i+1), n_estimators)\n", "        )\n", "        bagging = BaggingRegressor(\n", "            DecisionTreeRegressor(), \n", "            n_estimators=step_factor*(i+1),\n", "            n_jobs=n_jobs,\n", "            random_state=random_state\n", "        )\n", "        bagging.fit(X_train, y_train)\n", "        mse = mean_squared_error(y_test, bagging.predict(X_test))\n", "        estimators[i] = step_factor*(i+1)\n", "        bagging_mse[i] = mse\n\n", "    # Estimate the Random Forest MSE over the full number\n", "    # of estimators, across a step size (\"step_factor\")\n", "    for i in range(0, axis_step):\n", "        print(\"Random Forest Estimator: %d of %d...\" % (\n", "            step_factor*(i+1), n_estimators)\n", "        )\n", "        rf = RandomForestRegressor(\n", "            n_estimators=step_factor*(i+1),\n", "            n_jobs=n_jobs,\n", "            random_state=random_state\n", "        )\n", "        rf.fit(X_train, y_train)\n", "        mse = mean_squared_error(y_test, rf.predict(X_test))\n", "        estimators[i] = step_factor*(i+1)\n", "        rf_mse[i] = mse\n\n", "    # Estimate the AdaBoost MSE over the full number\n", "    # of estimators, across a step size (\"step_factor\")\n", "    for i in range(0, axis_step):\n", "        print(\"Boosting Estimator: %d of %d...\" % (\n", "            step_factor*(i+1), n_estimators)\n", "        )\n", "        boosting = AdaBoostRegressor(\n", "            DecisionTreeRegressor(),\n", "            n_estimators=step_factor*(i+1),\n", "            random_state=random_state,\n", "            learning_rate=0.01\n", "        )\n", "        boosting.fit(X_train, y_train)\n", "        mse = mean_squared_error(y_test, boosting.predict(X_test))\n", "        estimators[i] = step_factor*(i+1)\n", "        boosting_mse[i] = mse\n\n", "    # Plot the chart of MSE versus number of estimators\n", "    plt.figure(figsize=(8, 8))\n", "    plt.title('Bagging, Random Forest and Boosting comparison')\n", "    plt.plot(estimators, bagging_mse, 'b-', color=\"black\", label='Bagging')\n", "    plt.plot(estimators, rf_mse, 'b-', color=\"blue\", label='Random Forest')\n", "    plt.plot(estimators, boosting_mse, 'b-', color=\"red\", label='AdaBoost')\n", "    plt.legend(loc='upper right')\n", "    plt.xlabel('Estimators')\n", "    plt.ylabel('Mean Squared Error')\n", "    plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}